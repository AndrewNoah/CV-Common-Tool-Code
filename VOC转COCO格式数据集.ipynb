{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCdevkit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    " \n",
    "def _isArrayLike(obj):\n",
    "    return hasattr(obj, '__iter__') and hasattr(obj, '__len__')\n",
    " \n",
    " \n",
    "class voc2coco:\n",
    "    def __init__(self, devkit_path=None, year=None):\n",
    "        self.classes = ( #'__background__',  \n",
    "                        '2', '3', '4', '5',\n",
    "                        '6') #数据集类别\n",
    " \n",
    "        self.num_classes = len(self.classes)\n",
    "        print(devkit_path)\n",
    "        assert 'VOCdevkit' in devkit_path, 'VOC地址不存在: {}'.format(devkit_path)\n",
    "        self.data_path = os.path.join(devkit_path, 'VOC' + year)\n",
    "        self.annotaions_path = os.path.join(self.data_path, 'Annotations')\n",
    "        self.image_set_path = os.path.join(self.data_path, 'ImageSets')\n",
    "        self.year = year\n",
    "        self.categories_to_ids_map = self._get_categories_to_ids_map()\n",
    "        self.categories_msg = self._categories_msg_generator()\n",
    " \n",
    "    def _load_annotation(self, ids=[]):\n",
    "        ids = ids if _isArrayLike(ids) else [ids]\n",
    "        image_msg = []\n",
    "        annotation_msg = []\n",
    "        annotation_id = 1\n",
    "        for index in ids:\n",
    "            filename = '{:0>6}'.format(index)\n",
    "            json_file = os.path.join(self.data_path, 'Segmentation_json', filename + '.json')\n",
    "            if os.path.exists(json_file):\n",
    "                img_file = os.path.join(self.data_path, 'JPEGImages', filename + '.jpg')\n",
    "                im = cv2.imread(img_file)\n",
    "                width = im.shape[1]\n",
    "                height = im.shape[0]\n",
    "                seg_data = json.load(open(json_file, 'r'))\n",
    "                assert type(seg_data) == type(dict()), 'annotation file format {} not supported'.format(type(seg_data))\n",
    "                for shape in seg_data['shapes']:\n",
    "                    seg_msg = []\n",
    "                    for point in shape['points']:\n",
    "                        seg_msg += point\n",
    "                    one_ann_msg = {\"segmentation\": [seg_msg],\n",
    "                                   \"area\": self._area_computer(shape['points']),\n",
    "                                   \"iscrowd\": 0,\n",
    "                                   \"image_id\": str(index),\n",
    "                                   \"bbox\": self._points_to_mbr(shape['points']),\n",
    "                                   \"category_id\": self.categories_to_ids_map[shape['label']],\n",
    "                                   \"id\": annotation_id,\n",
    "                                   \"ignore\": 0\n",
    "                                   }\n",
    "                    annotation_msg.append(one_ann_msg)\n",
    "                    annotation_id += 1\n",
    "            else:\n",
    "                xml_file = os.path.join(self.annotaions_path, filename + '.xml')\n",
    "                tree = ET.parse(xml_file)\n",
    "                size = tree.find('size')\n",
    "                objs = tree.findall('object')\n",
    "                width = size.find('width').text\n",
    "                height = size.find('height').text\n",
    "                for obj in objs:\n",
    "                    bndbox = obj.find('bndbox')\n",
    "                    [xmin, xmax, ymin, ymax] \\\n",
    "                        = [int(bndbox.find('xmin').text) - 1, int(bndbox.find('xmax').text),\n",
    "                           int(bndbox.find('ymin').text) - 1, int(bndbox.find('ymax').text)]\n",
    "                    if xmin < 0:\n",
    "                        xmin = 0\n",
    "                    if ymin < 0:\n",
    "                        ymin = 0\n",
    "                    bbox = [xmin, xmax, ymin, ymax]\n",
    "                    one_ann_msg = {\"segmentation\": self._bbox_to_mask(bbox),\n",
    "                                   \"area\": self._bbox_area_computer(bbox),\n",
    "                                   \"iscrowd\": 0,\n",
    "                                   \"image_id\": str(index),\n",
    "                                   \"bbox\": [xmin, ymin, xmax - xmin, ymax - ymin],\n",
    "                                   \"category_id\": self.categories_to_ids_map[obj.find('name').text],\n",
    "                                   \"id\": annotation_id,\n",
    "                                   \"ignore\": 0\n",
    "                                   }\n",
    "                    annotation_msg.append(one_ann_msg)\n",
    "                    annotation_id += 1\n",
    "            one_image_msg = {\"file_name\": filename + \".jpg\",\n",
    "                             \"height\": int(height),\n",
    "                             \"width\": int(width),\n",
    "                             \"id\": str(index)\n",
    "                             }\n",
    "            image_msg.append(one_image_msg)\n",
    "        return image_msg, annotation_msg\n",
    "    def _bbox_to_mask(self, bbox):\n",
    "        assert len(bbox) == 4, 'Wrong bndbox!'\n",
    "        mask = [bbox[0], bbox[2], bbox[0], bbox[3], bbox[1], bbox[3], bbox[1], bbox[2]]\n",
    "        return [mask]\n",
    "    def _bbox_area_computer(self, bbox):\n",
    "        width = bbox[1] - bbox[0]\n",
    "        height = bbox[3] - bbox[2]\n",
    "        return width * height\n",
    "    def _save_json_file(self, filename=None, data=None):\n",
    "        json_path = os.path.join(self.data_path, 'cocoformatJson')\n",
    "        assert filename is not None, 'lack filename'\n",
    "        if os.path.exists(json_path) == False:\n",
    "            os.mkdir(json_path)\n",
    "        if not filename.endswith('.json'):\n",
    "            filename += '.json'\n",
    "        assert type(data) == type(dict()), 'data format {} not supported'.format(type(data))\n",
    "        with open(os.path.join(json_path, filename), 'w') as f:\n",
    "            f.write(json.dumps(data))\n",
    "    def _get_categories_to_ids_map(self):\n",
    "        return dict(zip(self.classes, range(self.num_classes)))\n",
    "    def _get_all_indexs(self):\n",
    "        ids = []\n",
    "        for root, dirs, files in os.walk(self.annotaions_path, topdown=False):\n",
    "            for f in files:\n",
    "                if str(f).endswith('.xml'):\n",
    "                    id = int(str(f).strip('.xml'))\n",
    "                    ids.append(id)\n",
    "        assert ids is not None, 'There is none xml file in {}'.format(self.annotaions_path)\n",
    "        return ids\n",
    "    def _get_indexs_by_image_set(self, image_set=None):\n",
    "        if image_set is None:\n",
    "            return self._get_all_indexs()\n",
    "        else:\n",
    "            image_set_path = os.path.join(self.image_set_path, 'Main', image_set + '.txt')\n",
    "            assert os.path.exists(image_set_path), 'Path does not exist: {}'.format(image_set_path)\n",
    "            with open(image_set_path) as f:\n",
    "                ids = [x.strip() for x in f.readlines()]\n",
    "            return ids\n",
    "    def _points_to_mbr(self, points):\n",
    "        assert _isArrayLike(points), 'Points should be array like!'\n",
    "        x = [point[0] for point in points]\n",
    "        y = [point[1] for point in points]\n",
    "        assert len(x) == len(y), 'Wrong point quantity'\n",
    "        xmin, xmax, ymin, ymax = min(x), max(x), min(y), max(y)\n",
    "        height = ymax - ymin\n",
    "        width = xmax - xmin\n",
    "        return [xmin, ymin, width, height]\n",
    "    def _categories_msg_generator(self):\n",
    "        categories_msg = []\n",
    "        for category in self.classes:\n",
    "            if category == '__background__':\n",
    "                continue\n",
    "            one_categories_msg = {\"supercategory\": \"none\",\n",
    "                                  \"id\": self.categories_to_ids_map[category],\n",
    "                                  \"name\": category\n",
    "                                  }\n",
    "            categories_msg.append(one_categories_msg)\n",
    "        return categories_msg\n",
    "    def _area_computer(self, points):\n",
    "        assert _isArrayLike(points), 'Points should be array like!'\n",
    "        tmp_contour = []\n",
    "        for point in points:\n",
    "            tmp_contour.append([point])\n",
    "        contour = np.array(tmp_contour, dtype=np.int32)\n",
    "        area = cv2.contourArea(contour)\n",
    "        return area\n",
    "    def voc_to_coco_converter(self):\n",
    "        img_sets = ['trainval', 'test']\n",
    "        for img_set in img_sets:\n",
    "            ids = self._get_indexs_by_image_set(img_set)\n",
    "            img_msg, ann_msg = self._load_annotation(ids)\n",
    "            result_json = {\"images\": img_msg,\n",
    "                           \"type\": \"instances\",\n",
    "                           \"annotations\": ann_msg,\n",
    "                           \"categories\": self.categories_msg}\n",
    "            self._save_json_file('voc_' + self.year + '_' + img_set, result_json)\n",
    "def demo():\n",
    "    # 转换pascal地址是'./VOC2007/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt'\n",
    "    converter = voc2coco('VOCdevkit', '2007')\n",
    "    converter.voc_to_coco_converter()\n",
    "if __name__ == \"__main__\":\n",
    "    demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xupeng/Desktop/Mac/python-jupyter代码'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.py                               VOC数据集划分.ipynb\n",
      "\u001b[34m111\u001b[m\u001b[m/                               b.csv\n",
      "93136326_S2_C2_P2.xml              csv2xml_voc.ipynb\n",
      "\u001b[34mFK\u001b[m\u001b[m/                                csv合并增列.ipynb\n",
      "GAN不规则图像预处理.ipynb          data1.txt\n",
      "\u001b[34mGC10-DET\u001b[m\u001b[m/                          mb.csv\n",
      "\u001b[34mGC2020_VOC\u001b[m\u001b[m/                        paddle书练习.ipynb\n",
      "\u001b[34mGJ2020_COCO\u001b[m\u001b[m/                       vockmeans聚类.ipynb\n",
      "JPEGImages.xlsx                    未命名.ipynb\n",
      "\u001b[34mMb\u001b[m\u001b[m/                                文件对比筛选.ipynb\n",
      "\u001b[34mVOC2007\u001b[m\u001b[m/                           图像和信息分块.ipynb\n",
      "VOC转COCO格式.ipynb                目标检测可视化.ipynb\n",
      "VOC转COCO格式数据集.ipynb          规则化批量提取文件.ipynb\n",
      "VOC数据制作.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
